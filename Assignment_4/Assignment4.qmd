---
title: "Assignment_04"
author: "Nicole Tang"
format: html
embed-resources: true
fig-width: 9
fig-height: 6
---

## Due Date

This assignment is due by 11:59pm Pacific Time, November 22nd, 2024.

The learning objectives are to write faster code for computational task requiring a loop and to implement some queries and basic data wrangling in SQL.

## HPC

### Make things run faster
Rewrite the following R functions to make them faster. It is OK (and recommended) to take a look at StackOverflow and Google

```{r}
# Total row sums
fun1 <- function(mat) {
  n <- nrow(mat)
  ans <- double(n) 
  for (i in 1:n) {
    ans[i] <- sum(mat[i, ])
  }
  ans
}

fun1alt <- function(mat) {
  # YOUR CODE HERE
  rowSums(mat)
}

# Cumulative sum by row
fun2 <- function(mat) {
  n <- nrow(mat)
  k <- ncol(mat)
  ans <- mat
  for (i in 1:n) {
    for (j in 2:k) {
      ans[i,j] <- mat[i, j] + ans[i, j - 1]
    }
  }
  ans
}

fun2alt <- function(mat) {
  # YOUR CODE HERE
  t(apply(mat, 1, cumsum))
}
```

### Question 1
Using the dataset generated below (`dat`), check that the output of both of your new functions matches the output of the original functions. Then use `microbenchmark` to check that your version is actually faster.

```{r}
# Use the data with this code
set.seed(2315)
dat <- matrix(rnorm(200 * 100), nrow = 200)

# Test for the first
microbenchmark::microbenchmark(
  fun1(dat),
  fun1alt(dat), unit = "relative"
)

# Test for the second
microbenchmark::microbenchmark(
  fun2(dat),
  fun2alt(dat), unit = "relative"
)
```
**When looking at the first function, fun1 has an average runtime of 26.12. fun1alt has a significantly faster runtime of 1.0. When looking at the second function, fun2 has an average runtime of 3.18. fun2alt has a significantly faster runtime of 1.0.**

### Make things run faster with parallel computing

The following function allows simulating pi:

```{r}
sim_pi <- function(n = 1000, i = NULL) {
  p <- matrix(runif(n*2), ncol = 2)
  mean(rowSums(p^2) < 1) * 4
}

# Here is an example of the run
set.seed(156)
sim_pi(1000) # 3.132
```

In order to get accurate estimates, we can run this function multiple times, with the following code:

```{r}
# This runs the simulation a 4,000 times, each with 10,000 points
set.seed(1231)
system.time({
  ans <- unlist(lapply(1:4000, sim_pi, n = 10000))
  print(mean(ans))
})
```

### Question 2
Rewrite the previous code using `parLapply()` (or your parallelization method of choice) to parallelize it. Run the code once, using `system.time()`, to show that your version is faster.

```{r}
# YOUR CODE HERE
library(parallel)
system.time({
  # YOUR CODE HERE
  cl <- makeCluster(detectCores() - 1)
  
  clusterExport(cl, varlist = c("sim_pi"))
  
  ans <- unlist(parLapply(cl, 1:4000, function(i) sim_pi(n = 10000)))
  
  print(mean(ans))
  # YOUR CODE HERE
  
  stopCluster(cl)
  
})
```

## SQL

Setup a temporary database by running the following chunk

```{r}
# install.packages(c("RSQLite", "DBI"))

library(RSQLite)
library(DBI)

# Initialize a temporary in memory database
con <- dbConnect(SQLite(), ":memory:")

# Download tables
film <- read.csv("https://raw.githubusercontent.com/ivanceras/sakila/master/csv-sakila-db/film.csv")
film_category <- read.csv("https://raw.githubusercontent.com/ivanceras/sakila/master/csv-sakila-db/film_category.csv")
category <- read.csv("https://raw.githubusercontent.com/ivanceras/sakila/master/csv-sakila-db/category.csv")

# Copy data.frames to database
dbWriteTable(con, "film", film)
dbWriteTable(con, "film_category", film_category)
dbWriteTable(con, "category", category)
```

When you write a new chunk, remember to replace the `r` with `sql, connection=con`. Some of these questions will require you to use an inner join. Read more about them here https://www.w3schools.com/sql/sql_join_inner.asp

## Question 3

How many many movies are available in each `rating` category?
```{sql, connection=con}
SELECT rating, COUNT(*) AS movie_count
FROM film
GROUP BY rating
ORDER BY movie_count DESC
```
**The following ratings have this many movies PG-13:	223			NC-17:	210			R:	195			PG:	194			G:	180	**

## Question 4

What is the average replacement cost and rental rate for each `rating` category?
```{sql, connection=con}
SELECT rating, 
         AVG(replacement_cost) AS avg_replacement_cost, 
         AVG(rental_rate) AS avg_rental_rate
FROM film
GROUP BY rating
ORDER BY rating
```
**The following ratings have the avg replacement cost and avg rental rate: G:	replacement_cost- 20.12333	rental_rate- 2.912222		NC-17:	replacement_cost- 20.13762	rental_rate- 2.970952		PG:	replacement_cost- 18.95907	rental_rate- 3.051856		PG-13:	replacement_cost- 20.40256	rental_rate- 3.034843		R:	replacement_cost- 20.23103	rental_rate- 2.938718**

## Question 5

Use table `film_category` together with `film` to find how many films there are with each category ID.
```{sql, connection=con}
SELECT fc.category_id, COUNT(fc.film_id) AS film_count
FROM film_category fc
JOIN film f ON fc.film_id = f.film_id
GROUP BY fc.category_id
ORDER BY film_count DESC
```

**Category 15 has the most films at 74 and category 12 has the least amount of films at 51.**

## Question 6

Incorporate the `category` table into the answer to the previous question to find the name of the most popular category.
```{sql, connection=con}
SELECT c.name AS category_name, COUNT(fc.film_id) AS film_count
FROM film_category fc
JOIN film f ON fc.film_id = f.film_id
JOIN category c ON fc.category_id = c.category_id
GROUP BY c.name
ORDER BY film_count DESC
LIMIT 1
```
**Sports is the most popular category.**

